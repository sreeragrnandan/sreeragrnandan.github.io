<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>TFJS</title>
    <add name="Access-Control-Allow-Origin" value="*" />
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js"></script>
</head>
<body>
    <script>
        
    // JavaScript
    // Access-Control-Allow-Origin:https
// Access-Control-Allow-Credentials-true
// Access-Control-Expose-Headers: FooBar
    // import * as tf from '@tensorflow/tfjs';
async function start() {
    // const proxyurl = "https://cors-anywhere.herokuapp.com/";
    // const url = 'https://github.com/sreeragrnandan/model/tree/master/tfjs'
    // const model_URL = fetch(proxyurl + url)
    const model = await tf.loadLayersModel("https://github.com/sreeragrnandan/model/tree/master/tfjs/model.json");
        // JavaScript
        maxPredictions = model.getTotalClasses();
        
                // Convenience function to setup a webcam
                const flip = true; // whether to flip the webcam
                webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
                await webcam.setup(); // request access to the webcam
                await webcam.play();
                window.requestAnimationFrame(loop);
        
                // append elements to the DOM
                document.getElementById("webcam-container").appendChild(webcam.canvas);
                labelContainer = document.getElementById("label-container");
                for (let i = 0; i < maxPredictions; i++) { // and class labels
                    labelContainer.appendChild(document.createElement("div"));
                }
    
}
async function loop() {
                webcam.update(); // update the webcam frame
                await predict();
                window.requestAnimationFrame(loop);
            }


// const example = tf.fromPixels(webcamElement);  // for example
// const prediction = model.predict(example);
async function predict() {
                // predict can take in an image, video or canvas html element
                const prediction = await model.predict(webcam.canvas);
                for (let i = 0; i < maxPredictions; i++) {
                    const classPrediction =
                        prediction[i].className + ": " + prediction[i].probability.toFixed(2);
                    labelContainer.childNodes[i].innerHTML = classPrediction;
                }
            }

    </script>
    <button type="button" onclick="start()">Start</button>
    <div id="webcam-container"></div>
    <div id="label-container"></div>
        <!-- <script type="text/javascript">
            // More API functions here:
            // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image
        
            // the link to your model provided by Teachable Machine export panel
            const URL = "./tfjs/";
            // JavaScript

            import * as tf from '@tensorflow/tfjs';

            const model = await tf.loadLayersModel('https://foo.bar/tfjs_artifacts/model.json');

            let model, webcam, labelContainer, maxPredictions;
        
            // Load the image model and setup the webcam
            async function init() {
                const modelURL = URL + "model.json";
                // const metadataURL = URL + "metadata.json";
        
                // load the model and metadata
                // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
                // or files from your local hard drive
                // Note: the pose library adds "tmImage" object to your window (window.tmImage)
                model = await tmImage.load(modelURL, metadataURL);
                maxPredictions = model.getTotalClasses();
        
                // Convenience function to setup a webcam
                const flip = true; // whether to flip the webcam
                webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
                await webcam.setup(); // request access to the webcam
                await webcam.play();
                window.requestAnimationFrame(loop);
        
                // append elements to the DOM
                document.getElementById("webcam-container").appendChild(webcam.canvas);
                labelContainer = document.getElementById("label-container");
                for (let i = 0; i < maxPredictions; i++) { // and class labels
                    labelContainer.appendChild(document.createElement("div"));
                }
            }
        
            async function loop() {
                webcam.update(); // update the webcam frame
                await predict();
                window.requestAnimationFrame(loop);
            }
        
            // run the webcam image through the image model
            async function predict() {
                // predict can take in an image, video or canvas html element
                const prediction = await model.predict(webcam.canvas);
                for (let i = 0; i < maxPredictions; i++) {
                    const classPrediction =
                        prediction[i].className + ": " + prediction[i].probability.toFixed(2);
                    labelContainer.childNodes[i].innerHTML = classPrediction;
                }
            }

    </script> -->
</body>
</html>
